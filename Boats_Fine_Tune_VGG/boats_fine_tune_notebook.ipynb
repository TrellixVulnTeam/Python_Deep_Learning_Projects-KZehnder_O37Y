{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/693\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "WARNING:tensorflow:From <ipython-input-1-52c3284ecff9>:101: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate on 174 samples\n",
      "Epoch 1/25\n",
      "16/16 [==============================] - 105s 7s/step - loss: 5.6297 - accuracy: 0.3696 - val_loss: 1.0544 - val_accuracy: 0.5287\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 97s 6s/step - loss: 1.0770 - accuracy: 0.5257 - val_loss: 0.6732 - val_accuracy: 0.7701\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 92s 6s/step - loss: 1.1407 - accuracy: 0.5421 - val_loss: 0.9235 - val_accuracy: 0.5460\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 1.0136 - accuracy: 0.5421 - val_loss: 0.6491 - val_accuracy: 0.7356\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.9177 - accuracy: 0.5791 - val_loss: 0.5588 - val_accuracy: 0.8161\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.8933 - accuracy: 0.5852 - val_loss: 0.7322 - val_accuracy: 0.6609\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 93s 6s/step - loss: 0.7128 - accuracy: 0.6879 - val_loss: 0.4897 - val_accuracy: 0.7989\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.7468 - accuracy: 0.6242 - val_loss: 0.5288 - val_accuracy: 0.7356\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.7186 - accuracy: 0.6899 - val_loss: 0.5061 - val_accuracy: 0.8046\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.6407 - accuracy: 0.7125 - val_loss: 0.5439 - val_accuracy: 0.7586\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 90s 6s/step - loss: 0.6786 - accuracy: 0.7064 - val_loss: 0.5152 - val_accuracy: 0.7529\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 95s 6s/step - loss: 0.6397 - accuracy: 0.7125 - val_loss: 0.4836 - val_accuracy: 0.7759\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 105s 7s/step - loss: 0.6445 - accuracy: 0.7310 - val_loss: 0.4875 - val_accuracy: 0.7759\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 111s 7s/step - loss: 0.6329 - accuracy: 0.7331 - val_loss: 0.5006 - val_accuracy: 0.7471\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 113s 7s/step - loss: 0.5832 - accuracy: 0.7331 - val_loss: 0.4091 - val_accuracy: 0.8448\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 106s 7s/step - loss: 0.5365 - accuracy: 0.7536 - val_loss: 0.4423 - val_accuracy: 0.7931\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 107s 7s/step - loss: 0.5685 - accuracy: 0.7290 - val_loss: 0.4104 - val_accuracy: 0.8506\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 107s 7s/step - loss: 0.4827 - accuracy: 0.7803 - val_loss: 0.4213 - val_accuracy: 0.8563\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 106s 7s/step - loss: 0.4876 - accuracy: 0.7823 - val_loss: 0.4948 - val_accuracy: 0.7931\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 106s 7s/step - loss: 0.5201 - accuracy: 0.7721 - val_loss: 0.4066 - val_accuracy: 0.8448\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 106s 7s/step - loss: 0.5813 - accuracy: 0.7556 - val_loss: 0.4098 - val_accuracy: 0.8563\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 108s 7s/step - loss: 0.4501 - accuracy: 0.7885 - val_loss: 0.4035 - val_accuracy: 0.8506\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 105s 7s/step - loss: 0.5331 - accuracy: 0.7598 - val_loss: 0.4668 - val_accuracy: 0.8218\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 107s 7s/step - loss: 0.5647 - accuracy: 0.7639 - val_loss: 0.4007 - val_accuracy: 0.8506\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 106s 7s/step - loss: 0.4870 - accuracy: 0.7803 - val_loss: 0.4484 - val_accuracy: 0.8276\n",
      "[INFO] evaluating after initialization...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Canoe       0.86      0.93      0.90        46\n",
      "     Jet ski       0.95      0.80      0.86        44\n",
      "   Steamboat       0.72      0.92      0.81        37\n",
      "     Tugboat       0.80      0.68      0.74        47\n",
      "\n",
      "    accuracy                           0.83       174\n",
      "   macro avg       0.83      0.83      0.83       174\n",
      "weighted avg       0.84      0.83      0.83       174\n",
      "\n",
      "[INFO] re-compiling model...\n",
      "[INFO] fine-tuning model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate on 174 samples\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 123s 8s/step - loss: 0.4430 - accuracy: 0.8090 - val_loss: 0.4023 - val_accuracy: 0.8448\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 121s 8s/step - loss: 0.4269 - accuracy: 0.8131 - val_loss: 0.3955 - val_accuracy: 0.8448\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 121s 8s/step - loss: 0.4069 - accuracy: 0.8193 - val_loss: 0.3763 - val_accuracy: 0.8506\n",
      "Epoch 4/100\n",
      "13/16 [=======================>......] - ETA: 18s - loss: 0.3620 - accuracy: 0.8465"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python3 finetune_boats.py --dataset ../datasets/boats/images \\\n",
    "# \t--model boats.model\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.datasets import SimpleDatasetLoader\n",
    "from pyimagesearch.nn.conv import FCHeadNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "# do your work here\n",
    "\n",
    "dataset = '../datasets/boats/images/'\n",
    "model_output_path = 'git_output/boats/boats_fine_tune.model'\n",
    "figure_output_path = 'git_output/boats/boats_fine_tune_plot.png'\n",
    "csv_init_output_path = 'git_output/boats/boats_fine_tune_head.csv'\n",
    "csv_final_output_path = 'git_output/boats/boats_fine_tune_final.csv'\n",
    "NUM_INIT_EPOCHS = 25\n",
    "NUM_TUNE_EPOCHS = 100\n",
    "DIMS = (224, 224)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# grab the list of images that we'll be describing, then extract\n",
    "# the class label names from the image paths\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "# initialize the image preprocessors\n",
    "aap = AspectAwarePreprocessor(DIMS[0], DIMS[1])\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities to\n",
    "# the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(DIMS[0], DIMS[1], 3)))\n",
    "\n",
    "# initialize the new head of the network, a set of FC layers\n",
    "# followed by a softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames), 256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will\n",
    "# become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they\n",
    "# will *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other\n",
    "# layers are frozen) -- this will allow the new FC layers to\n",
    "# start to become initialized with actual \"learned\" values\n",
    "# versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "\tvalidation_data=(testX, testY), epochs=NUM_INIT_EPOCHS,\n",
    "\tsteps_per_epoch=len(trainX) // 32, verbose=1)\n",
    "\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=classNames))\n",
    "\n",
    "# output classification report to CSV\n",
    "report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), \n",
    "    output_dict=True, target_names=classNames)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(csv_init_output_path)\n",
    "\n",
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "\tlayer.trainable = True\n",
    "\n",
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the model again, this time fine-tuning *both* the final set\n",
    "# of CONV layers along with our set of FC layers\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "\tvalidation_data=(testX, testY), epochs=NUM_TUNE_EPOCHS,\n",
    "\tsteps_per_epoch=len(trainX) // 32, verbose=1)\n",
    "\n",
    "# evaluate the network on the fine-tuned model\n",
    "print(\"[INFO] evaluating after fine-tuning...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=classNames))\n",
    "\n",
    "# output classification report to CSV\n",
    "report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), \n",
    "    output_dict=True, target_names=classNames)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(csv_final_output_path)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('*'* 50, '\\n[INFO] Duration: {}'.format(end_time - start_time), '\\n', '*'*50)\n",
    "\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to...{}\".format(model_output_path))\n",
    "model.save(model_output_path)\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, NUM_TUNE_EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.ylim(None, 2)\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(figure_output_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
