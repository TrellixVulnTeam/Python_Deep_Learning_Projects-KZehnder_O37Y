{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/1727\n",
      "[INFO] processed 1000/1727\n",
      "[INFO] processed 1500/1727\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "WARNING:tensorflow:From <ipython-input-1-b17a1beb9e47>:103: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate on 432 samples\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 436s 11s/step - loss: 3.4945 - accuracy: 0.3405 - val_loss: 1.3836 - val_accuracy: 0.4167\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 438s 11s/step - loss: 1.4489 - accuracy: 0.4331 - val_loss: 1.2591 - val_accuracy: 0.5046\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 438s 11s/step - loss: 1.2529 - accuracy: 0.4917 - val_loss: 1.0501 - val_accuracy: 0.5741\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 429s 11s/step - loss: 1.2182 - accuracy: 0.4901 - val_loss: 0.9241 - val_accuracy: 0.6597\n",
      "Epoch 5/25\n",
      "40/40 [==============================] - 434s 11s/step - loss: 1.1358 - accuracy: 0.5297 - val_loss: 0.8925 - val_accuracy: 0.6366\n",
      "Epoch 6/25\n",
      "40/40 [==============================] - 438s 11s/step - loss: 1.1092 - accuracy: 0.5360 - val_loss: 0.8784 - val_accuracy: 0.6366\n",
      "Epoch 7/25\n",
      "40/40 [==============================] - 434s 11s/step - loss: 1.0720 - accuracy: 0.5598 - val_loss: 0.8090 - val_accuracy: 0.6759\n",
      "Epoch 8/25\n",
      "40/40 [==============================] - 434s 11s/step - loss: 1.0134 - accuracy: 0.5820 - val_loss: 0.9084 - val_accuracy: 0.6852\n",
      "Epoch 9/25\n",
      "40/40 [==============================] - 478s 12s/step - loss: 1.0499 - accuracy: 0.5534 - val_loss: 0.8512 - val_accuracy: 0.6690\n",
      "Epoch 10/25\n",
      "40/40 [==============================] - 478s 12s/step - loss: 1.0026 - accuracy: 0.5804 - val_loss: 0.7831 - val_accuracy: 0.6829\n",
      "Epoch 11/25\n",
      "40/40 [==============================] - 453s 11s/step - loss: 1.0017 - accuracy: 0.5812 - val_loss: 0.7772 - val_accuracy: 0.6782\n",
      "Epoch 12/25\n",
      "40/40 [==============================] - 431s 11s/step - loss: 0.9830 - accuracy: 0.6025 - val_loss: 0.7418 - val_accuracy: 0.7176\n",
      "Epoch 13/25\n",
      "40/40 [==============================] - 440s 11s/step - loss: 0.9493 - accuracy: 0.6215 - val_loss: 0.7391 - val_accuracy: 0.7199\n",
      "Epoch 14/25\n",
      "40/40 [==============================] - 432s 11s/step - loss: 0.9382 - accuracy: 0.6176 - val_loss: 0.7421 - val_accuracy: 0.6806\n",
      "Epoch 15/25\n",
      "40/40 [==============================] - 504s 13s/step - loss: 0.9542 - accuracy: 0.6073 - val_loss: 0.6882 - val_accuracy: 0.7315\n",
      "Epoch 16/25\n",
      "40/40 [==============================] - 467s 12s/step - loss: 0.9161 - accuracy: 0.6120 - val_loss: 0.7607 - val_accuracy: 0.6898\n",
      "Epoch 17/25\n",
      "40/40 [==============================] - 433s 11s/step - loss: 0.9260 - accuracy: 0.6160 - val_loss: 0.6891 - val_accuracy: 0.7130\n",
      "Epoch 18/25\n",
      "40/40 [==============================] - 437s 11s/step - loss: 0.9148 - accuracy: 0.6318 - val_loss: 0.7658 - val_accuracy: 0.7176\n",
      "Epoch 19/25\n",
      "40/40 [==============================] - 434s 11s/step - loss: 0.9177 - accuracy: 0.6200 - val_loss: 0.7263 - val_accuracy: 0.7037\n",
      "Epoch 20/25\n",
      "40/40 [==============================] - 440s 11s/step - loss: 0.8572 - accuracy: 0.6500 - val_loss: 0.7208 - val_accuracy: 0.7292\n",
      "Epoch 21/25\n",
      "40/40 [==============================] - 428s 11s/step - loss: 0.9071 - accuracy: 0.6342 - val_loss: 0.7880 - val_accuracy: 0.6898\n",
      "Epoch 22/25\n",
      "40/40 [==============================] - 428s 11s/step - loss: 0.8690 - accuracy: 0.6429 - val_loss: 0.7675 - val_accuracy: 0.7130\n",
      "Epoch 23/25\n",
      "40/40 [==============================] - 428s 11s/step - loss: 0.8796 - accuracy: 0.6421 - val_loss: 0.7436 - val_accuracy: 0.7130\n",
      "Epoch 24/25\n",
      "40/40 [==============================] - 429s 11s/step - loss: 0.8743 - accuracy: 0.6540 - val_loss: 0.7850 - val_accuracy: 0.6968\n",
      "Epoch 25/25\n",
      "40/40 [==============================] - 428s 11s/step - loss: 0.8635 - accuracy: 0.6223 - val_loss: 0.7021 - val_accuracy: 0.7153\n",
      "[INFO] evaluating after initialization...\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Inflatable boat       0.57      0.72      0.63        53\n",
      "        Jet ski       0.86      0.84      0.85        79\n",
      "    Patrol boat       0.53      0.46      0.49        59\n",
      "       Sailboat       0.89      0.71      0.79        55\n",
      "      Steamboat       0.88      0.74      0.80        61\n",
      "        Tugboat       0.66      0.75      0.70       125\n",
      "\n",
      "       accuracy                           0.72       432\n",
      "      macro avg       0.73      0.70      0.71       432\n",
      "   weighted avg       0.73      0.72      0.72       432\n",
      "\n",
      "[INFO] re-compiling model...\n",
      "[INFO] fine-tuning model...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate on 432 samples\n",
      "Epoch 1/80\n",
      "40/40 [==============================] - 502s 13s/step - loss: 0.7723 - accuracy: 0.6770 - val_loss: 0.7277 - val_accuracy: 0.7014\n",
      "Epoch 2/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.7524 - accuracy: 0.6968 - val_loss: 0.6712 - val_accuracy: 0.7361\n",
      "Epoch 3/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.7087 - accuracy: 0.6991 - val_loss: 0.6788 - val_accuracy: 0.7292\n",
      "Epoch 4/80\n",
      "40/40 [==============================] - 494s 12s/step - loss: 0.7515 - accuracy: 0.6852 - val_loss: 0.6645 - val_accuracy: 0.7431\n",
      "Epoch 5/80\n",
      "40/40 [==============================] - 500s 12s/step - loss: 0.7386 - accuracy: 0.6983 - val_loss: 0.6436 - val_accuracy: 0.7361\n",
      "Epoch 6/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.7104 - accuracy: 0.7023 - val_loss: 0.6511 - val_accuracy: 0.7338\n",
      "Epoch 7/80\n",
      "40/40 [==============================] - 502s 13s/step - loss: 0.6688 - accuracy: 0.7094 - val_loss: 0.6601 - val_accuracy: 0.7338\n",
      "Epoch 8/80\n",
      "40/40 [==============================] - 503s 13s/step - loss: 0.7185 - accuracy: 0.7109 - val_loss: 0.6495 - val_accuracy: 0.7361\n",
      "Epoch 9/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.7059 - accuracy: 0.7063 - val_loss: 0.6562 - val_accuracy: 0.7361\n",
      "Epoch 10/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.6984 - accuracy: 0.6944 - val_loss: 0.6625 - val_accuracy: 0.7361\n",
      "Epoch 11/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.6703 - accuracy: 0.7229 - val_loss: 0.6507 - val_accuracy: 0.7384\n",
      "Epoch 12/80\n",
      "40/40 [==============================] - 494s 12s/step - loss: 0.6668 - accuracy: 0.7118 - val_loss: 0.6380 - val_accuracy: 0.7454\n",
      "Epoch 13/80\n",
      "40/40 [==============================] - 494s 12s/step - loss: 0.6577 - accuracy: 0.7197 - val_loss: 0.6430 - val_accuracy: 0.7269\n",
      "Epoch 14/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.6458 - accuracy: 0.7292 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 15/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.6481 - accuracy: 0.7245 - val_loss: 0.6107 - val_accuracy: 0.7639\n",
      "Epoch 16/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.6131 - accuracy: 0.7340 - val_loss: 0.6281 - val_accuracy: 0.7569\n",
      "Epoch 17/80\n",
      "40/40 [==============================] - 491s 12s/step - loss: 0.6171 - accuracy: 0.7506 - val_loss: 0.6553 - val_accuracy: 0.7431\n",
      "Epoch 18/80\n",
      "40/40 [==============================] - 499s 12s/step - loss: 0.6442 - accuracy: 0.7284 - val_loss: 0.6301 - val_accuracy: 0.7870\n",
      "Epoch 19/80\n",
      "40/40 [==============================] - 500s 12s/step - loss: 0.6075 - accuracy: 0.7371 - val_loss: 0.6376 - val_accuracy: 0.7431\n",
      "Epoch 20/80\n",
      "40/40 [==============================] - 500s 13s/step - loss: 0.6486 - accuracy: 0.7260 - val_loss: 0.6364 - val_accuracy: 0.7569\n",
      "Epoch 21/80\n",
      "40/40 [==============================] - 502s 13s/step - loss: 0.6107 - accuracy: 0.7411 - val_loss: 0.6487 - val_accuracy: 0.7639\n",
      "Epoch 22/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.6539 - accuracy: 0.7213 - val_loss: 0.6205 - val_accuracy: 0.7500\n",
      "Epoch 23/80\n",
      "40/40 [==============================] - 499s 12s/step - loss: 0.5847 - accuracy: 0.7553 - val_loss: 0.6239 - val_accuracy: 0.7500\n",
      "Epoch 24/80\n",
      "40/40 [==============================] - 499s 12s/step - loss: 0.6021 - accuracy: 0.7530 - val_loss: 0.6095 - val_accuracy: 0.7616\n",
      "Epoch 25/80\n",
      "40/40 [==============================] - 491s 12s/step - loss: 0.6126 - accuracy: 0.7443 - val_loss: 0.6143 - val_accuracy: 0.7847\n",
      "Epoch 26/80\n",
      "40/40 [==============================] - 505s 13s/step - loss: 0.5605 - accuracy: 0.7672 - val_loss: 0.6814 - val_accuracy: 0.7593\n",
      "Epoch 27/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.5780 - accuracy: 0.7577 - val_loss: 0.6311 - val_accuracy: 0.7801\n",
      "Epoch 28/80\n",
      "40/40 [==============================] - 490s 12s/step - loss: 0.5663 - accuracy: 0.7514 - val_loss: 0.6291 - val_accuracy: 0.7662\n",
      "Epoch 29/80\n",
      "40/40 [==============================] - 494s 12s/step - loss: 0.5955 - accuracy: 0.7506 - val_loss: 0.6556 - val_accuracy: 0.7847\n",
      "Epoch 30/80\n",
      "40/40 [==============================] - 503s 13s/step - loss: 0.5489 - accuracy: 0.7805 - val_loss: 0.6353 - val_accuracy: 0.7569\n",
      "Epoch 31/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.5856 - accuracy: 0.7704 - val_loss: 0.6080 - val_accuracy: 0.7685\n",
      "Epoch 32/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.5490 - accuracy: 0.7728 - val_loss: 0.5981 - val_accuracy: 0.7639\n",
      "Epoch 33/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.5756 - accuracy: 0.7617 - val_loss: 0.5956 - val_accuracy: 0.7894\n",
      "Epoch 34/80\n",
      "40/40 [==============================] - 498s 12s/step - loss: 0.5723 - accuracy: 0.7609 - val_loss: 0.6103 - val_accuracy: 0.7639\n",
      "Epoch 35/80\n",
      "40/40 [==============================] - 491s 12s/step - loss: 0.5612 - accuracy: 0.7688 - val_loss: 0.6122 - val_accuracy: 0.7778\n",
      "Epoch 36/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.5665 - accuracy: 0.7609 - val_loss: 0.6271 - val_accuracy: 0.7523\n",
      "Epoch 37/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.5573 - accuracy: 0.7783 - val_loss: 0.6210 - val_accuracy: 0.7593\n",
      "Epoch 38/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.5432 - accuracy: 0.7823 - val_loss: 0.6194 - val_accuracy: 0.7731\n",
      "Epoch 39/80\n",
      "40/40 [==============================] - 487s 12s/step - loss: 0.5376 - accuracy: 0.7846 - val_loss: 0.6159 - val_accuracy: 0.7546\n",
      "Epoch 40/80\n",
      "40/40 [==============================] - 485s 12s/step - loss: 0.5524 - accuracy: 0.7807 - val_loss: 0.6808 - val_accuracy: 0.7546\n",
      "Epoch 41/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.5279 - accuracy: 0.7775 - val_loss: 0.6448 - val_accuracy: 0.7662\n",
      "Epoch 42/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.4947 - accuracy: 0.7823 - val_loss: 0.6651 - val_accuracy: 0.7546\n",
      "Epoch 43/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.5089 - accuracy: 0.7949 - val_loss: 0.6359 - val_accuracy: 0.7546\n",
      "Epoch 44/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.5224 - accuracy: 0.8005 - val_loss: 0.6524 - val_accuracy: 0.7755\n",
      "Epoch 45/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.5415 - accuracy: 0.7823 - val_loss: 0.6250 - val_accuracy: 0.7639\n",
      "Epoch 46/80\n",
      "40/40 [==============================] - 491s 12s/step - loss: 0.5253 - accuracy: 0.7791 - val_loss: 0.6022 - val_accuracy: 0.7847\n",
      "Epoch 47/80\n",
      "40/40 [==============================] - 486s 12s/step - loss: 0.5277 - accuracy: 0.7870 - val_loss: 0.6276 - val_accuracy: 0.7847\n",
      "Epoch 48/80\n",
      "40/40 [==============================] - 491s 12s/step - loss: 0.5109 - accuracy: 0.7815 - val_loss: 0.6127 - val_accuracy: 0.7801\n",
      "Epoch 49/80\n",
      "40/40 [==============================] - 488s 12s/step - loss: 0.5147 - accuracy: 0.7751 - val_loss: 0.6355 - val_accuracy: 0.7731\n",
      "Epoch 50/80\n",
      "40/40 [==============================] - 494s 12s/step - loss: 0.5371 - accuracy: 0.7862 - val_loss: 0.6445 - val_accuracy: 0.7500\n",
      "Epoch 51/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.5193 - accuracy: 0.7831 - val_loss: 0.6109 - val_accuracy: 0.7523\n",
      "Epoch 52/80\n",
      "40/40 [==============================] - 501s 13s/step - loss: 0.4951 - accuracy: 0.8021 - val_loss: 0.6020 - val_accuracy: 0.7824\n",
      "Epoch 53/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.4643 - accuracy: 0.8092 - val_loss: 0.6759 - val_accuracy: 0.7523\n",
      "Epoch 54/80\n",
      "40/40 [==============================] - 498s 12s/step - loss: 0.4976 - accuracy: 0.7949 - val_loss: 0.6812 - val_accuracy: 0.7801\n",
      "Epoch 55/80\n",
      "40/40 [==============================] - 488s 12s/step - loss: 0.5314 - accuracy: 0.7743 - val_loss: 0.6346 - val_accuracy: 0.7639\n",
      "Epoch 56/80\n",
      "40/40 [==============================] - 489s 12s/step - loss: 0.4878 - accuracy: 0.8029 - val_loss: 0.6271 - val_accuracy: 0.7616\n",
      "Epoch 57/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.4748 - accuracy: 0.8171 - val_loss: 0.6432 - val_accuracy: 0.7523\n",
      "Epoch 58/80\n",
      "40/40 [==============================] - 491s 12s/step - loss: 0.4835 - accuracy: 0.8060 - val_loss: 0.6368 - val_accuracy: 0.7616\n",
      "Epoch 59/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.4810 - accuracy: 0.8029 - val_loss: 0.7106 - val_accuracy: 0.7801\n",
      "Epoch 60/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.4747 - accuracy: 0.8076 - val_loss: 0.6755 - val_accuracy: 0.7778\n",
      "Epoch 61/80\n",
      "40/40 [==============================] - 484s 12s/step - loss: 0.4493 - accuracy: 0.8211 - val_loss: 0.6645 - val_accuracy: 0.7685\n",
      "Epoch 62/80\n",
      "40/40 [==============================] - 492s 12s/step - loss: 0.4578 - accuracy: 0.8124 - val_loss: 0.7483 - val_accuracy: 0.7477\n",
      "Epoch 63/80\n",
      "40/40 [==============================] - 490s 12s/step - loss: 0.4929 - accuracy: 0.7886 - val_loss: 0.7487 - val_accuracy: 0.7616\n",
      "Epoch 64/80\n",
      "40/40 [==============================] - 497s 12s/step - loss: 0.4571 - accuracy: 0.8084 - val_loss: 0.6531 - val_accuracy: 0.7639\n",
      "Epoch 65/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.4752 - accuracy: 0.8076 - val_loss: 0.6549 - val_accuracy: 0.7639\n",
      "Epoch 66/80\n",
      "40/40 [==============================] - 488s 12s/step - loss: 0.4838 - accuracy: 0.8005 - val_loss: 0.6136 - val_accuracy: 0.7778\n",
      "Epoch 67/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.4697 - accuracy: 0.8155 - val_loss: 0.6636 - val_accuracy: 0.7731\n",
      "Epoch 68/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.4453 - accuracy: 0.8131 - val_loss: 0.6430 - val_accuracy: 0.7940\n",
      "Epoch 69/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.4436 - accuracy: 0.8139 - val_loss: 0.6401 - val_accuracy: 0.7593\n",
      "Epoch 70/80\n",
      "40/40 [==============================] - 495s 12s/step - loss: 0.4955 - accuracy: 0.7799 - val_loss: 0.6116 - val_accuracy: 0.7569\n",
      "Epoch 71/80\n",
      "40/40 [==============================] - 497s 12s/step - loss: 0.4460 - accuracy: 0.8131 - val_loss: 0.6348 - val_accuracy: 0.7662\n",
      "Epoch 72/80\n",
      "40/40 [==============================] - 493s 12s/step - loss: 0.4823 - accuracy: 0.7949 - val_loss: 0.7072 - val_accuracy: 0.7731\n",
      "Epoch 73/80\n",
      "40/40 [==============================] - 494s 12s/step - loss: 0.4672 - accuracy: 0.8274 - val_loss: 0.6625 - val_accuracy: 0.7685\n",
      "Epoch 74/80\n",
      "40/40 [==============================] - 489s 12s/step - loss: 0.4255 - accuracy: 0.8274 - val_loss: 0.6610 - val_accuracy: 0.7870\n",
      "Epoch 75/80\n",
      "40/40 [==============================] - 496s 12s/step - loss: 0.4675 - accuracy: 0.8155 - val_loss: 0.6493 - val_accuracy: 0.7685\n",
      "Epoch 76/80\n",
      "40/40 [==============================] - 488s 12s/step - loss: 0.4573 - accuracy: 0.8203 - val_loss: 0.6257 - val_accuracy: 0.7662\n",
      "Epoch 77/80\n",
      "40/40 [==============================] - 483s 12s/step - loss: 0.4343 - accuracy: 0.8282 - val_loss: 0.6403 - val_accuracy: 0.7917\n",
      "Epoch 78/80\n",
      "40/40 [==============================] - 490s 12s/step - loss: 0.4375 - accuracy: 0.8258 - val_loss: 0.6572 - val_accuracy: 0.7778\n",
      "Epoch 79/80\n",
      "40/40 [==============================] - 479s 12s/step - loss: 0.4476 - accuracy: 0.8242 - val_loss: 0.6833 - val_accuracy: 0.7847\n",
      "Epoch 80/80\n",
      "40/40 [==============================] - 490s 12s/step - loss: 0.4174 - accuracy: 0.8195 - val_loss: 0.6607 - val_accuracy: 0.7870\n",
      "[INFO] evaluating after fine-tuning...\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Inflatable boat       0.72      0.64      0.68        53\n",
      "        Jet ski       0.83      0.95      0.89        79\n",
      "    Patrol boat       0.61      0.76      0.68        59\n",
      "       Sailboat       0.90      0.82      0.86        55\n",
      "      Steamboat       0.88      0.80      0.84        61\n",
      "        Tugboat       0.80      0.74      0.77       125\n",
      "\n",
      "       accuracy                           0.79       432\n",
      "      macro avg       0.79      0.79      0.78       432\n",
      "   weighted avg       0.79      0.79      0.79       432\n",
      "\n",
      "[INFO] serializing network to...\n",
      "WARNING:tensorflow:From /home/bluehand/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: git_output/boats/boats_vgg16net_fine_tune_notebook.model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# USAGE\n",
    "# python finetune_flowers17.py --dataset ../datasets/flowers17/images \\\n",
    "# \t--model flowers17.model\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pyimagesearch.preprocessing import ImageToArrayPreprocessor\n",
    "from pyimagesearch.preprocessing import AspectAwarePreprocessor\n",
    "from pyimagesearch.datasets import SimpleDatasetLoader\n",
    "from pyimagesearch.nn.conv import FCHeadNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "# do your work here\n",
    "\n",
    "\n",
    "dataset = '../datasets/boats/train/'\n",
    "model_output_path = 'git_output/boats/boats_vgg16net_fine_tune_notebook.model'\n",
    "figure_output_path = 'git_output/boats/boats_vgg16net_finetune_fruit_training_plot.png'\n",
    "head_init_report_path = 'git_output/boats/boats_head_init_report.csv'\n",
    "final_report_path = 'git_output/boats/boats_final_report.csv'\n",
    "HEAD_INIT_EPOCHS = 25\n",
    "NUM_EPOCHS = 80\n",
    "DIMS = (224, 224)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# grab the list of images that we'll be describing, then extract\n",
    "# the class label names from the image paths\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(dataset))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "# initialize the image preprocessors\n",
    "aap = AspectAwarePreprocessor(DIMS[0], DIMS[1])\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities to\n",
    "# the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(DIMS[0], DIMS[1], 3)))\n",
    "\n",
    "# initialize the new head of the network, a set of FC layers\n",
    "# followed by a softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames), 256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will\n",
    "# become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they\n",
    "# will *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other\n",
    "# layers are frozen) -- this will allow the new FC layers to\n",
    "# start to become initialized with actual \"learned\" values\n",
    "# versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "    validation_data=(testX, testY), epochs=HEAD_INIT_EPOCHS,\n",
    "    steps_per_epoch=len(trainX) // 32, verbose=1)\n",
    "\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "    predictions.argmax(axis=1), target_names=classNames))\n",
    "\n",
    "# output classification report to CSV\n",
    "report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), \n",
    "    output_dict=True, target_names=classNames)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(head_init_report_path)\n",
    "\n",
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# for the changes to the model to take affect we need to recompile\n",
    "# the model, this time using SGD with a *very* small learning rate\n",
    "print(\"[INFO] re-compiling model...\")\n",
    "opt = SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model again, this time fine-tuning *both* the final set\n",
    "# of CONV layers along with our set of FC layers\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "    validation_data=(testX, testY), epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=len(trainX) // 32, verbose=1)\n",
    "\n",
    "# evaluate the network on the fine-tuned model\n",
    "print(\"[INFO] evaluating after fine-tuning...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "    predictions.argmax(axis=1), target_names=classNames))\n",
    "\n",
    "# output classification report to CSV\n",
    "report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), \n",
    "    output_dict=True, target_names=classNames)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(final_report_path)\n",
    "\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to...\")\n",
    "model.save(model_output_path)\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, NUM_EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(figure_output_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
